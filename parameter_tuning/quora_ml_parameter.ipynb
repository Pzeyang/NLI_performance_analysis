{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and testing data\n",
    "data = pd.read_csv('../Data/train.csv')\n",
    "data.dropna(inplace = True)\n",
    "#data = data[:30000]\n",
    "train, test = train_test_split(data, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_accuracy(y_pred, y_actual):\n",
    "    \"\"\"Function to calculate the accuracy of a model, returns the accuracy\n",
    "        Args: \n",
    "            y_pred: predicted values\n",
    "            y_actual: actual values\"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_actual[i]:\n",
    "            count = count+1\n",
    "    return (count/len(y_pred))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing\n",
    "q = list(train['question1']) + list(train['question2']) + list(test['question1']) + list(test['question2'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30000)\n",
    "\n",
    "vectorizer.fit(q)\n",
    "\n",
    "train_q = train['question1'] + \" \" + train['question2']\n",
    "test_q = test['question1']+ \" \" + test['question2']\n",
    "\n",
    "sent_q_train = vectorizer.transform(train_q)\n",
    "sent_q_test = vectorizer.transform(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "C = [0.001,0.01,0.1,1,10,100]\n",
    "random_state = 0\n",
    "max_iter = 1000\n",
    "penality = 'l2'\n",
    "#penality = 'elasticnet'\n",
    "acc_saga = []\n",
    "acc_lgbf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkpat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Saga\n",
    "accuracy = {}\n",
    "for solver in solvers:\n",
    "    acc = []\n",
    "    for i in C:\n",
    "        lr = LogisticRegression(penalty = 'l2', \n",
    "                                C =i, \n",
    "                                random_state=random_state,\n",
    "                                max_iter=max_iter, solver = solver)\n",
    "        \n",
    "        lr.fit(sent_q_train, train['is_duplicate'])\n",
    "    \n",
    "        result_lr = lr.predict(sent_q_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_lr, list(test['is_duplicate'].to_numpy())))\n",
    "        \n",
    "    accuracy[solver] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'liblinear': [63.19455437707773,\n",
       "  70.73670254867817,\n",
       "  74.22332594586038,\n",
       "  75.8657194870983,\n",
       "  76.81652683235714,\n",
       "  76.8422510685452],\n",
       " 'newton-cg': [63.16784074719012,\n",
       "  70.72384043058413,\n",
       "  74.2213471584613,\n",
       "  75.8627513059997,\n",
       "  76.81751622605667,\n",
       "  76.84818743074244],\n",
       " 'lbfgs': [63.166851353490586,\n",
       "  70.72384043058413,\n",
       "  74.22530473325946,\n",
       "  75.85879373120153,\n",
       "  76.81157986385942,\n",
       "  76.85412379293969],\n",
       " 'sag': [63.16784074719012,\n",
       "  70.72384043058413,\n",
       "  74.2213471584613,\n",
       "  75.8627513059997,\n",
       "  76.81751622605667,\n",
       "  76.84917682444198],\n",
       " 'saga': [63.16784074719012,\n",
       "  70.72384043058413,\n",
       "  74.2213471584613,\n",
       "  75.86374069969922,\n",
       "  76.81553743865759,\n",
       "  76.84917682444198]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.001,0.01,0.1,1,10,100]\n",
    "kernels = ['linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saga\n",
    "accuracy = {}\n",
    "for kernel in kernels:\n",
    "    acc = []\n",
    "    for i in C:\n",
    "        svc = SVC(C = i, kernel = kernel )\n",
    "        \n",
    "        svc.fit(sent_q_train, train['is_duplicate'])\n",
    "        \n",
    "        result_svm = svc.predict(sent_q_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_svm, list(test['is_duplicate'].to_numpy())))\n",
    "        \n",
    "    accuracy[kernel] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.84925270080566\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "aa = time.time()\n",
    "svc = SVC(C = .1, kernel = 'linear' )\n",
    "\n",
    "svc.fit(sent_q_train, train['is_duplicate'])\n",
    "\n",
    "result_svm = svc.predict(sent_q_test)\n",
    "bb = time.time()\n",
    "print(bb-aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 400, 600, 800, 1000]\n",
    "max_depth = [10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "100\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "100\n",
      "200\n",
      "400\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for depth in max_depth:\n",
    "    acc = []\n",
    "    for i in n_estimators:\n",
    "        print(i)\n",
    "        rf = RandomForestClassifier(n_estimators=i, \n",
    "                                   bootstrap = True,\n",
    "                                           max_features = 'sqrt',\n",
    "                                    max_depth = depth)\n",
    "        \n",
    "        rf.fit(sent_q_train, train['is_duplicate'])\n",
    "        \n",
    "        result_svm = rf.predict(sent_q_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_svm, list(test['is_duplicate'].to_numpy())))\n",
    "        \n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [.0001, .001, .01, .1]\n",
    "drop_out = ['l2', 'l1-l2', 'l1']\n",
    "\n",
    "learning_rate    = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, .001, .01, 1 ]\n",
    "max_depth        = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight = [ 1, 3, 5, 7 ]\n",
    "gamma            = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "colsample_bytree = [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "n_estimators = [100, 200, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy =[]\n",
    "for i in n_estimators:\n",
    "    acc = []\n",
    "    for j in learning_rate: \n",
    "        xgb = XGBClassifier(n_estimators=i, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt',\n",
    "                               max_depth = 3,\n",
    "                               learning_rate = j)\n",
    "\n",
    "        svc.fit(sent_q_train, train['is_duplicate'])\n",
    "\n",
    "        result_svm = svc.predict(sent_q_test)\n",
    "\n",
    "        acc.append(gen_accuracy(result_svm, list(test['is_duplicate'].to_numpy())))\n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [.0001, .001, .01, .1, 1, 10]\n",
    "n_estimators = [100, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for n_est in n_estimators:\n",
    "    acc = []\n",
    "    for i in learning_rate:\n",
    "        ada = AdaBoostClassifier(n_estimators = n_est, learning_rate = i)\n",
    "        ada.fit(sent_q_train, train['is_duplicate'])\n",
    "        result_ada = ada.predict(sent_q_test)\n",
    "        acc.append(gen_accuracy(result_ada, test['is_duplicate'].to_numpy()))\n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=3,learning_rate=0.01,n_estimators=312)                      \n",
    "\n",
    "ada_boost = AdaBoostClassifier()\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                       bootstrap = True,\n",
    "                       max_features = 'sqrt')\n",
    "lr = LogisticRegression(solver = 'saga', penalty = 'elasticnet', l1_ratio=.5, random_state=0)\n",
    "\n",
    "rf = random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                       bootstrap = True,\n",
    "                       max_features = 'sqrt')\n",
    "\n",
    "svm= SVC(probability=True)\n",
    "\n",
    "\n",
    "model = VotingClassifier(estimators=[('logistic', lr), \n",
    "                                     ('ada', ada_boost),\n",
    "                                     ('random_forest', rf),\n",
    "                                     ('xgb', xgb),\n",
    "                                     ('svm', svm)], \n",
    "               voting='soft', weights=[1,1,3,1,1]).fit(sent_vect_train,train['Quality'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
