{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning MSR Paraphrase\n",
    "\n",
    "<p>The best parameters for the machine learning alogorithms for the msr paraphrase data. The following machine learning algorithms models will be tuned:\n",
    "<ul> <li> Logisitc Regression</li>\n",
    "    <li> Support vector classification </li>\n",
    "    <li> Random Forest</li>\n",
    "    <li> XGB Classifier</li>\n",
    "    <li> Adaboost Classifier </li>\n",
    "    <li> Voting Classifier </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Loading the msr paraphrase data. It contains texts which are taken from online news websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and testing data\n",
    "train = pd.read_csv(r'../Data/msr_paraphrase_train.txt', sep = '\\t', quoting=csv.QUOTE_NONE)\n",
    "test = pd.read_csv(r'../Data/msr_paraphrase_test.txt', sep = '\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_accuracy(y_pred, y_actual):\n",
    "    \"\"\"Function to calculate the accuracy of a model, returns the accuracy\n",
    "        Args: \n",
    "            y_pred: predicted values\n",
    "            y_actual: actual values\"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_actual[i]:\n",
    "            count = count+1\n",
    "    return (count/len(y_pred))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing\n",
    "sent = list(train['#1 String']) + list(train['#2 String']) + list(test['#1 String']) + list(test['#2 String'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30000)\n",
    "\n",
    "vectorizer.fit(sent)\n",
    "\n",
    "train_sent = train['#1 String'] + \" \" + train['#2 String']\n",
    "test_sent = test['#1 String']+ \" \" + test['#2 String']\n",
    "\n",
    "sent_vect_train = vectorizer.transform(train_sent)\n",
    "sent_vect_test = vectorizer.transform(test_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The parameters that are tested:\n",
    "<ul> <li> solvers </li>\n",
    "    <li> C</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "C = [0.001,0.01,0.1,1,10,100]\n",
    "random_state = 0\n",
    "max_iter = 1000\n",
    "penality = 'l2'\n",
    "#penality = 'elasticnet'\n",
    "acc_saga = []\n",
    "acc_lgbf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saga\n",
    "accuracy = {}\n",
    "for solver in solvers:\n",
    "    acc = []\n",
    "    for i in C:\n",
    "        lr = LogisticRegression(penalty = 'l2', \n",
    "                                C =i, \n",
    "                                random_state=random_state,\n",
    "                                max_iter=max_iter, solver = solver)\n",
    "        \n",
    "        lr.fit(sent_vect_train, train['Quality'])\n",
    "    \n",
    "        lr.fit(sent_vect_train, train['Quality'])\n",
    "        \n",
    "        result_lr = lr.predict(sent_vect_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_lr, list(test['Quality'].to_numpy())))\n",
    "        \n",
    "    accuracy[solver] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'liblinear': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.11594202898551,\n",
       "  68.57971014492755,\n",
       "  67.76811594202898,\n",
       "  66.26086956521739],\n",
       " 'newton-cg': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.05797101449275,\n",
       "  68.57971014492755,\n",
       "  67.76811594202898,\n",
       "  66.26086956521739],\n",
       " 'lbfgs': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.05797101449275,\n",
       "  68.57971014492755,\n",
       "  67.76811594202898,\n",
       "  66.26086956521739],\n",
       " 'sag': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.05797101449275,\n",
       "  68.57971014492755,\n",
       "  67.76811594202898,\n",
       "  66.43478260869566],\n",
       " 'saga': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.11594202898551,\n",
       "  68.57971014492755,\n",
       "  67.76811594202898,\n",
       "  66.31884057971014]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.001,0.01,0.1,1,10,100]\n",
    "kernels = ['linear', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saga\n",
    "accuracy = {}\n",
    "for kernel in kernels:\n",
    "    acc = []\n",
    "    for i in C:\n",
    "        svc = SVC(C = i, kernel = kernel )\n",
    "        \n",
    "        svc.fit(sent_vect_train, train['Quality'])\n",
    "        \n",
    "        result_svm = svc.predict(sent_vect_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_svm, list(test['Quality'].to_numpy())))\n",
    "        \n",
    "    accuracy[kernel] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.0,\n",
       "  68.69565217391305,\n",
       "  64.0,\n",
       "  63.36231884057971],\n",
       " 'rbf': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  67.42028985507247,\n",
       "  69.44927536231884,\n",
       "  70.31884057971014,\n",
       "  70.66666666666667],\n",
       " 'sigmoid': [66.4927536231884,\n",
       "  66.4927536231884,\n",
       "  68.0,\n",
       "  68.98550724637681,\n",
       "  63.94202898550725,\n",
       "  59.59420289855073]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "<p> <font size =3> Parameters considered:\n",
    "<ul> <li> n_estimators </li>\n",
    "    <li> max_depth </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 400, 600, 800, 1000]\n",
    "max_depth = [10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for depth in max_depth:\n",
    "    acc = []\n",
    "    for i in n_estimators:\n",
    "        rf = RandomForestClassifier(n_estimators=i, \n",
    "                                   bootstrap = True,\n",
    "                                           max_features = 'sqrt',\n",
    "                                    max_depth = depth)\n",
    "        \n",
    "        rf.fit(sent_vect_train, train['Quality'])\n",
    "        \n",
    "        result_svm = rf.predict(sent_vect_test)\n",
    "        \n",
    "        acc.append(gen_accuracy(result_svm, list(test['Quality'].to_numpy())))\n",
    "        \n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67.88405797101449,\n",
       "  67.88405797101449,\n",
       "  68.11594202898551,\n",
       "  68.05797101449275,\n",
       "  68.17391304347827,\n",
       "  68.17391304347827],\n",
       " [69.3913043478261,\n",
       "  69.44927536231884,\n",
       "  69.3913043478261,\n",
       "  69.04347826086956,\n",
       "  69.21739130434783,\n",
       "  68.98550724637681],\n",
       " [69.97101449275362,\n",
       "  69.85507246376812,\n",
       "  70.02898550724638,\n",
       "  70.02898550724638,\n",
       "  69.79710144927537,\n",
       "  70.02898550724638],\n",
       " [70.89855072463767,\n",
       "  70.78260869565217,\n",
       "  70.72463768115942,\n",
       "  71.01449275362319,\n",
       "  70.72463768115942,\n",
       "  70.78260869565217]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [.0001, .001, .01, .1]\n",
    "\n",
    "learning_rate    = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, .001, .01, 1 ]\n",
    "max_depth        = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "min_child_weight = [ 1, 3, 5, 7 ]\n",
    "gamma            = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "colsample_bytree = [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "n_estimators = [100, 200, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy =[]\n",
    "for j in learning_rate:\n",
    "    xgb = XGBClassifier(n_estimators=100, \n",
    "                           bootstrap = True,\n",
    "                           max_features = 'sqrt',\n",
    "                           max_depth = 3,\n",
    "                           learning_rate = j)\n",
    "\n",
    "    xgb.fit(sent_vect_train, train['Quality'])\n",
    "\n",
    "    result_svm = xgb.predict(sent_vect_test)\n",
    "\n",
    "    accuracy.append(gen_accuracy(result_svm, list(test['Quality'].to_numpy())))\n",
    "#accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69.91304347826087,\n",
       " 69.73913043478261,\n",
       " 70.3768115942029,\n",
       " 70.14492753623188,\n",
       " 69.79710144927537,\n",
       " 69.5072463768116,\n",
       " 68.57971014492755,\n",
       " 68.92753623188406,\n",
       " 68.28985507246377]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, bootstrap=True, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=15,\n",
       "              max_features='sqrt', min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb = XGBClassifier(n_estimators=100, \n",
    "#                                bootstrap = True,\n",
    "#                                max_features = 'sqrt',\n",
    "#                                max_depth = 15,\n",
    "#                                min_child_weight = 7,\n",
    "#                                 learning_rate = .3,\n",
    "#                                            gamma = .1,\n",
    "#                                            colsample_bytree = .7)\n",
    "# xgb.fit(sent_vect_train, train['Quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgb.predict(sent_vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.98550724637681"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_accuracy(result, test['Quality'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [.0001, .001, .01, .1, 1, 10]\n",
    "n_estimators = [100, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for n_est in n_estimators:\n",
    "    acc = []\n",
    "    for i in learning_rate:\n",
    "        ada = AdaBoostClassifier(n_estimators = n_est, learning_rate = i)\n",
    "        ada.fit(sent_vect_train, train['Quality'])\n",
    "        result_ada = ada.predict(sent_vect_test)\n",
    "        acc.append(gen_accuracy(result_ada, test['Quality'].to_numpy()))\n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[68.23188405797102,\n",
       "  68.23188405797102,\n",
       "  68.6376811594203,\n",
       "  68.81159420289855,\n",
       "  66.89855072463769,\n",
       "  32.231884057971016],\n",
       " [68.23188405797102,\n",
       "  68.23188405797102,\n",
       "  68.92753623188406,\n",
       "  68.98550724637681,\n",
       "  67.3623188405797,\n",
       "  32.231884057971016],\n",
       " [68.23188405797102,\n",
       "  68.34782608695652,\n",
       "  68.8695652173913,\n",
       "  69.6231884057971,\n",
       "  65.85507246376811,\n",
       "  32.231884057971016],\n",
       " [68.23188405797102,\n",
       "  68.34782608695652,\n",
       "  68.81159420289855,\n",
       "  69.33333333333334,\n",
       "  65.85507246376811,\n",
       "  32.231884057971016]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=3,learning_rate=0.01,n_estimators=312)                      \n",
    "\n",
    "ada_boost = AdaBoostClassifier()\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                       bootstrap = True,\n",
    "                       max_features = 'sqrt')\n",
    "lr = LogisticRegression(solver = 'saga', penalty = 'elasticnet', l1_ratio=.5, random_state=0)\n",
    "\n",
    "rf = random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                       bootstrap = True,\n",
    "                       max_features = 'sqrt')\n",
    "\n",
    "svm= SVC(probability=True)\n",
    "\n",
    "\n",
    "model = VotingClassifier(estimators=[('logistic', lr), \n",
    "                                     ('ada', ada_boost),\n",
    "                                     ('random_forest', rf),\n",
    "                                     ('xgb', xgb),\n",
    "                                     ('svm', svm)], \n",
    "               voting='soft', weights=[1,1,3,1,1]).fit(sent_vect_train,train['Quality'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
